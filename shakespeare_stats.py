#from pyspark import *
import re

import nltk
from nltk.stem.porter import  *
stemmer = PorterStemmer()

stopwords = [
"i",
"me",
"my",
"myself",
"we",
"our",
"ours",
"ourselves",
"you",
"your",
"yours",
"yourself",
"yourselves",
"he",
"him",
"his",
"himself",
"she",
"her",
"hers",
"herself",
"it",
"its",
"itself",
"they",
"them",
"their",
"theirs",
"themselves",
"what",
"which",
"who",
"whom",
"this",
"that",
"these",
"those",
"am",
"is",
"are",
"was",
"were",
"be",
"been",
"being",
"have",
"has",
"had",
"having",
"do",
"does",
"did",
"doing",
"a",
"an",
"the",
"and",
"but",
"if",
"or",
"because",
"as",
"until",
"while",
"of",
"at",
"by",
"for",
"with",
"about",
"against",
"between",
"into",
"through",
"during",
"before",
"after",
"above",
"below",
"to",
"from",
"up",
"down",
"in",
"out",
"on",
"off",
"over",
"under",
"again",
"further",
"then",
"once",
"here",
"there",
"when",
"where",
"why",
"how",
"all",
"any",
"both",
"each",
"few",
"more",
"most",
"other",
"some",
"such",
"no",
"nor",
"not",
"only",
"own",
"same",
"so",
"than",
"too",
"very",
"s",
"t",
"can",
"will",
"just",
"don",
"should",
"now",
"this",
"d",
"though",
"shall"
]

lines = sc.textFile("Complete_Shakespeare.txt")

lines_no_punc = lines.map(lambda line: re.sub(r"[^a-zA-Z0-9]", " ", line.lower()))
words_no_punc = lines_no_punc.flatMap(lambda line: line.split())
words_no_stop = words_no_punc.filter(lambda word: word not in stopwords)
words_no_stop = words_no_punc.filter(lambda word: word not in stopwords)
words_stem = words_no_stop.map( lambda x: stemmer.stem(x) )
words_count = words_stem.map(lambda x: (x,1)).reduceByKey(lambda x,y:x+y).map(lambda x: (x[1],x[0])).sortByKey(ascending=False)
words_count.take(5)


